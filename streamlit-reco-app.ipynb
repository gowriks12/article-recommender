{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9cf3e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from streamlit import session_state as session\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de4871e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-d7d23262024d>:13: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['date'] = pd.to_datetime(df['date'])\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"medium_data.csv\", index_col=\"id\")\n",
    "\n",
    "def fix_titles(title):\n",
    "    # Define a pattern to match HTML tags\n",
    "    html_tags_pattern = re.compile(r'<.*?>')\n",
    "    \n",
    "    # Replace HTML tags with an empty string\n",
    "    cleaned_title = re.sub(html_tags_pattern, '', title)\n",
    "    \n",
    "    return cleaned_title\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['title'] = df['title'].apply(fix_titles)\n",
    "    df[\"claps\"] = df[\"claps\"].fillna(0)\n",
    "    df[\"subtitle\"] = df[\"subtitle\"].fillna(df[\"title\"])\n",
    "    return df\n",
    "data = data.drop_duplicates()\n",
    "df = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c1ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_content(df):\n",
    "    pub_popularity = df.groupby('publication')[['claps', 'responses']].mean().round().astype(int).sort_values(by='claps', ascending=False)\n",
    "    top_three_publications = pub_popularity['claps'].nlargest(3).index\n",
    "    channels = top_three_publications.tolist()\n",
    "    top_articles = pd.DataFrame()  # Initialize an empty DataFrame to store top articles\n",
    "    \n",
    "    for channel in channels:\n",
    "        cont = df[df['publication'] == channel]\n",
    "        top_n_articles = cont.nlargest(3, 'claps')  # Select top 3 articles for the channel\n",
    "        top_articles = pd.concat([top_articles, top_n_articles])  # Concatenate with previous top articles\n",
    "    \n",
    "    return top_articles\n",
    "        \n",
    "# print(top_content(df))\n",
    "\n",
    "def trending_article(df):\n",
    "    latest_date = df['date'].max()\n",
    "    latest_week = latest_date - pd.Timedelta(days=6)\n",
    "    latest_articles = df[df['date'] >= latest_week]\n",
    "    top_three = df.loc[latest_articles['claps'].nlargest(3).index]\n",
    "    top_three_trending = top_three['title'].tolist()\n",
    "    return top_three\n",
    "\n",
    "# print(trending_article(df))\n",
    "\n",
    "def popular_quick_reads(df):\n",
    "    quick_reads = df[df['reading_time'] <= 5.0]\n",
    "    quick_reads_df = df.loc[quick_reads['claps'].nlargest(3).index]\n",
    "#     popular_quick_reads = quick_reads_df['title'].tolist()\n",
    "    return quick_reads_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "030fc2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_publication_content = top_content(df)\n",
    "trending_articles = trending_article(df)\n",
    "top_quick_reads = popular_quick_reads(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf28af4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gowri\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "def content_based(df):\n",
    "    # Create a new feature article which is combination of both title and subtitle\n",
    "    df['article'] = df['title'] + df['subtitle']\n",
    "    # Sort Data by number of claps\n",
    "    df = df.sort_values(by=\"claps\", ascending=False)\n",
    "    # Now, we have to vectorize the articles using Tf-IDF vecotizer.\n",
    "    # Pre processing and NMF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    articles = vectorizer.fit_transform(df[\"article\"])\n",
    "    # Now we can apply NMF on our data and create the recommender. I choose 10 as number of components.\n",
    "    model = NMF(n_components=10, random_state=0)\n",
    "    nmf_features = model.fit_transform(articles)\n",
    "#     model.components_\n",
    "    normalized = normalize(nmf_features)\n",
    "    recom_df = pd.DataFrame(data=normalized)\n",
    "    recom_df.set_index(df['title'], inplace=True)\n",
    "    recom_df.to_csv(\"data/recom_df.csv\")\n",
    "    \n",
    "content_based(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "938e53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_articles(recom_df, article):    \n",
    "    similarities = recom_df.dot(article)\n",
    "    sims = pd.DataFrame(similarities.nlargest(10))\n",
    "    sims = sims.merge(df[[\"title\", \"claps\"]], how='inner', on=\"title\")\n",
    "    sims.set_index(\"title\", drop=True, inplace=True)\n",
    "    sims.sort_values(by=\"claps\", ascending=False)\n",
    "    return sims\n",
    "recom_df = pd.read_csv(\"data/recom_df.csv\", index_col=0)\n",
    "recom_df\n",
    "article = recom_df.loc[df['title'][419]]\n",
    "articles = recommend_articles(recom_df, article)\n",
    "# articles = recommend_articles(df.loc[df['title'][419]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6106a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>claps</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>How ChatGPT Works: The Model Behind The Bot</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TikTok’s unprecedented ability to engineer the “Consent of the Masses”</th>\n",
       "      <td>0.999169</td>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summarizing the latest Spotify releases with ChatGPT</th>\n",
       "      <td>0.997739</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balancing complexity and simplicity in chart design</th>\n",
       "      <td>0.997261</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generative Q&amp;A With GPT 3.5 and Long-Term Memory</th>\n",
       "      <td>0.996355</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visualizing direction and the use of arrows</th>\n",
       "      <td>0.996254</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Are Expert Systems Dead?</th>\n",
       "      <td>0.995508</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifying Drivers of Spotify Song Popularity With Causal ML</th>\n",
       "      <td>0.994542</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>How Duolingo drives subscription conversion</th>\n",
       "      <td>0.994361</td>\n",
       "      <td>516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>How to avoid getting designs shot down in the name of consistency</th>\n",
       "      <td>0.994243</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           0   claps\n",
       "title                                                               \n",
       "How ChatGPT Works: The Model Behind The Bot         1.000000  7100.0\n",
       "TikTok’s unprecedented ability to engineer the ...  0.999169   282.0\n",
       "Summarizing the latest Spotify releases with Ch...  0.997739    67.0\n",
       "Balancing complexity and simplicity in chart de...  0.997261   100.0\n",
       "Generative Q&A With GPT 3.5 and Long-Term Memory    0.996355   119.0\n",
       "Visualizing direction and the use of arrows         0.996254   372.0\n",
       "Are Expert Systems Dead?                            0.995508    29.0\n",
       "Identifying Drivers of Spotify Song Popularity ...  0.994542    50.0\n",
       "How Duolingo drives subscription conversion         0.994361   516.0\n",
       "How to avoid getting designs shot down in the n...  0.994243   140.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b66945da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 00:24:29.120 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "import types\n",
    "# @st.cache(persist=True, show_spinner=False, suppress_st_warning=True)\n",
    "# def load_data():\n",
    "#     \"\"\"\n",
    "#     load and cache data\n",
    "#     :return: tfidf data\n",
    "#     \"\"\"\n",
    "#     recom_df = pd.read_csv(\"data/recom_df.csv\", index_col=0)\n",
    "#     article_list = recom_df.index.tolist()\n",
    "#     return recom_df, article_list\n",
    "\n",
    "# recom_df, article_list = load_data()\n",
    "\n",
    "\n",
    "def my_hash_func(func):\n",
    "    # Custom hash function for functions\n",
    "    return hash(func.__code__)\n",
    "\n",
    "@st.cache_data(persist=True, show_spinner=False, hash_funcs={types.FunctionType: my_hash_func})\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    load and cache data\n",
    "    :return: tfidf data\n",
    "    \"\"\"\n",
    "    recom_df = pd.read_csv(\"data/recom_df.csv\", index_col=0)\n",
    "    article_list = recom_df.index.tolist()\n",
    "    return recom_df, article_list\n",
    "\n",
    "recom_df, article_list = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bf4f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = None\n",
    "\n",
    "st.title(\"\"\"\n",
    "Medium Article Recommendation System\n",
    "This is an Content Based Recommender System based on claps and responses :smile:.\n",
    " \"\"\")\n",
    "\n",
    "st.text(\"\")\n",
    "st.text(\"\")\n",
    "st.text(\"\")\n",
    "st.text(\"\")\n",
    "\n",
    "session.options = st.multiselect(label=\"Select Article\", options=article_list)\n",
    "\n",
    "st.text(\"\")\n",
    "st.text(\"\")\n",
    "\n",
    "session.slider_count = st.slider(label=\"Article Count\", min_value=5, max_value=10)\n",
    "\n",
    "st.text(\"\")\n",
    "st.text(\"\")\n",
    "\n",
    "buffer1, col1, buffer2 = st.columns([1.45, 1, 1])\n",
    "\n",
    "is_clicked = col1.button(label=\"Recommend\")\n",
    "\n",
    "if is_clicked:\n",
    "    dataframe = recommend_articles(recom_df=recom_df, article = session.options)\n",
    "\n",
    "st.text(\"\")\n",
    "st.text(\"\")\n",
    "st.text(\"\")\n",
    "st.text(\"\")\n",
    "\n",
    "if dataframe is not None:\n",
    "    st.table(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74637442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
